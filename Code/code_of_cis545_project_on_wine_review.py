# -*- coding: utf-8 -*-
"""Code_of_CIS545_Project_On_Wine_Review.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AGMrmuvkpnf5HAUrfh1_AYdwUHTPp9Ol

# PART 1: Data Wrangling, Transforming, Information Extraction
"""

# Commented out IPython magic to ensure Python compatibility.
# Data Wrangling
import pandas as pd
import numpy as np
import re

#nltk
import nltk
from nltk.corpus import stopwords
from nltk.sentiment import SentimentIntensityAnalyzer

#Counter
from collections import Counter

#Plotting
import seaborn as sns
import matplotlib.pyplot as plt
from wordcloud import WordCloud
# from IPython.display import Image
# import pydotplus
# %matplotlib inline

# Run this cell to mount the drive (will be prompted to sign in)
from google.colab import drive
drive.mount('/content/drive')

!pip install kaggle

# Create the kaggle directory and read the uploaded kaggle.json file
# (NOTE: Do NOT run this cell more than once unless restarting kernel)
!mkdir ~/.kaggle

# Read the uploaded kaggle.json file
!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/

# Download dataset
!!kaggle datasets download -d zynicide/wine-reviews

!unzip /content/wine-reviews.zip

# Read the csv files and concat them to a dataframe called `raw_wine_data`
raw_wine_data1 = pd.read_csv('winemag-data_first150k.csv')
raw_wine_data2 = pd.read_csv('winemag-data-130k-v2.csv')
# print(len(raw_wine_data1))
# print(len(raw_wine_data2))
raw_wine_data = pd.concat([raw_wine_data1, raw_wine_data2])
# Check out the first five rows
raw_wine_data = raw_wine_data.reset_index(drop=True)
raw_wine_data.head(5)

raw_wine_data.info()

# update index for each individual record
raw_wine_data = raw_wine_data.reset_index()
raw_wine_data

"""To have an idea about the relationship between the region and winery, we count how may kinds of wine were produced by a region-winery pair."""

region_winery = raw_wine_data[['region_1', 'winery']]
region_winery['count'] = pd.Series([0 for i in range(len(region_winery.index))])
region_winery_count = region_winery.groupby(['region_1','winery']).count().reset_index()

region_winery_count.describe()

region_winery_count['count'].plot(kind='kde', xlim=(0,30))

wineries_per_region = region_winery_count[['region_1', 'winery']].groupby('region_1').count().reset_index()
wineries_per_region.describe()

wineries_per_region['winery'].plot(kind='kde', xlim=(0,30))

regions_per_winery = region_winery_count[['winery', 'region_1']].groupby('winery').count().reset_index()
regions_per_winery.describe()

regions_per_winery['region_1'].plot(kind='kde', xlim=(0,10))

raw_wine_data_dropCol = raw_wine_data.drop(columns=['Unnamed: 0','designation','province','region_1','region_2','taster_twitter_handle','taster_name'])
raw_wine_data_dropCol.rename(columns={'index':'id'}, inplace=True)

raw_wine_data_dropCol

raw_wine_data_dropCol.info()

# keep the null data in "title"
raw_wine_data_dropCol_dropNa = raw_wine_data_dropCol.dropna(subset=['id', 'country', 'description', 'points', 'price', 'variety', 'winery'])
raw_wine_data_dropCol_dropNa.info()

# country_top20 list
country_top20 = raw_wine_data_dropCol_dropNa.groupby('country').count().sort_values('title',ascending=False)[0:20].reset_index()['country']
country_top20_list = country_top20.tolist()
country_top20_list

# get the data from top 20 countries
wine_data_top20countries = raw_wine_data_dropCol_dropNa[raw_wine_data_dropCol_dropNa['country'].isin(country_top20_list)]

entry_country_df = wine_data_top20countries[['id','country']].groupby(['country']).count().reset_index()
entry_country_df.rename(columns={'id':'entry count'}, inplace=True)
sns.set(rc={"figure.figsize":(15, 6)}, style="whitegrid")
g3 = sns.catplot(data=entry_country_df, x='country', y='entry count', height=8, aspect=1.5, kind='bar', dodge=False, log=True)
g3.set_xticklabels(rotation=90)
g3.set(title = 'entry count by country')

# variety_top20 list
variety_top20 = wine_data_top20countries.groupby('variety').count().sort_values('title',ascending=False)[0:20].reset_index()['variety']
variety_top20_list = variety_top20.tolist()

variety_top20_list

wine_data_top20 = wine_data_top20countries[wine_data_top20countries['variety'].isin(variety_top20_list)]
wine_data_top20.head(5)

def extract_year(title):
    if title == np.nan: return np.nan
    digits = re.findall(r'\d{4}', title)
    if len(digits)>0: return digits[0]
    return np.nan

wine_data_top20  = wine_data_top20.astype({'title':'str'})
wine_data_top20['year'] = wine_data_top20['title'].apply(extract_year)
wine_data_top20['year'] = wine_data_top20['year'].astype('Int64')
wine_data_top20.drop(columns=['title'], inplace=True)

wine_data_top20.describe()

wine_data_top20[(wine_data_top20['year']<1980)|(wine_data_top20['year']>2022)]

wine_data_top20['year'] = wine_data_top20['year'].astype('str')
wine_data_top20['year'] = wine_data_top20['year'].apply(lambda x:x if '1980'<x<'2022' else np.nan)
wine_data_top20['year'] = wine_data_top20['year'].astype('Int64')

wine_data_top20.describe()

wine_data_top20.info()

wine_data_top20.fillna(value={'year':0}, inplace=True)
wine_data_top20['missing_year']=wine_data_top20['year'].apply(lambda x:1 if x==0 else 0)

wine_data_top20.head(5)

wine_data_top20.info()

nltk.download('stopwords')
nltk.download('punkt')
nltk.download('vader_lexicon')
nltk.download('averaged_perceptron_tagger')
stopwords = set(stopwords.words('english'))

# TO-DO: extract description	
description_df = wine_data_top20[['id', 'description']]
description_df['description'] = description_df.apply(lambda x: str(x['description']), axis=1)
description_df

# Convert to dataframe & tokenize list 
# return a tokenized list of words, removing stop words and checking for alphabets
# in description_df, create a new column called 'tokenized' which contains the tokens from description.

from nltk.tokenize import word_tokenize 
def tokenize_content(content):
  word_list = word_tokenize(content)
  word_list = list(map(lambda x: x.lower(), word_list))
  # print(word_list)
  word_list_final = []
  count = 0;
  # print(len(word_list))
  while count < len(word_list):
    # print(count)
    word = word_list[count]
    # print(word_list[count])
    if word in stopwords:
      count = count + 1
      continue
    if word.isalpha() == True:
      word_list_final.append(word)
    count = count + 1
  # print(word_list_final)
  return word_list_final

  
#TODO: Apply the function to description
description_df['tokenized'] = description_df.apply(lambda x: tokenize_content(x['description']), axis=1)
description_df.info()

# nltk pos tag the tokenized words
# from nltk import pos_tag
description_df['tagged'] = description_df.apply(lambda x: nltk.pos_tag(x['tokenized']), axis=1)
description_df.head(5)

# Sentiment analysis
sia = SentimentIntensityAnalyzer()
def retrieve_sentiment(content):
  return sia.polarity_scores(content)['compound']

description_df['sentiment'] = description_df.apply(lambda x: retrieve_sentiment(x['description']), axis=1)
description_df.head(5)

wine_df = wine_data_top20[['id', 'country', 'points', 'price', 'variety', 'year', 'missing_year', 'winery']].merge(description_df[['id','sentiment']], on='id',how='left')

wine_df.head(5)

wine_df.info()

# # select adjective words for prediction

description_df['adjectives'] = description_df.apply(lambda x: set([word for word,tag in x['tagged'] if tag[0] in "JJ"]), axis=1)
description_df.head(5)

# from textblob import TextBlob
# def get_adjectives(text):
#     blob = TextBlob(str(text))
#     return set([ word for (word,tag) in blob.tags if tag == "JJ"])

# description_df['adjectives'] = description_df['description'].apply(get_adjectives)
# description_df

# TODO: flatten adjectives set
adjective_set_list = description_df["adjectives"].values.tolist()
adjective_list = []
for adjective_subset in adjective_set_list:
  for adj in adjective_subset:
    adjective_list.append(adj)
# adjective_list

#  Save the result as a list of (word, count) tuples, in descending order of count.
cnt = Counter()
for word in adjective_list:
  cnt[word] += 1

word_frequency_list = cnt.most_common()
# word_frequency_list

# generate wordCloud
wordcloud = WordCloud(background_color ='white').generate_from_frequencies(cnt)

# plot the WordCloud image                      
plt.figure(figsize = (8, 8), facecolor = None)
plt.imshow(wordcloud)
plt.axis("off")
plt.tight_layout(pad = 0)
plt.show()

winery_points = wine_df[['winery','points']].groupby('winery').mean().round(2).reset_index()
winery_points.rename(columns={'points':'winery_point'},inplace=True)

winery_points.head(5)

# Merge with wine_df, add one more column winery_point
wine_df = wine_df.merge(winery_points, how="left", on='winery')
wine_df.drop(columns=['winery'],inplace=True)

wine_df.head(5)

price_year_variety_df = wine_df[['price', 'variety', 'year']]
price_year_variety_df = price_year_variety_df[price_year_variety_df['year']>1980]
price_year_variety_df = price_year_variety_df[price_year_variety_df['variety'].isin(['Pinot Noir','Chardonnay','Cabernet Sauvignon','Riesling','Sauvignon Blanc','Syrah','Merlot','Zinfandel','Malbec'])]
price_year_variety_df['year']=price_year_variety_df['year'].astype('int64')
price_year_variety_df = price_year_variety_df.groupby(['variety', 'year']).mean().reset_index()
price_year_variety_df.rename(columns={'price':'average price','year':'production year'},inplace=True)

sns.set(rc={"figure.figsize":(15, 6)}, style="whitegrid")
g1 = sns.lineplot(data=price_year_variety_df, x='production year', y='average price', hue='variety')
g1.legend(fontsize=8)
g1.set(title = 'average price trend by production year')

price_variety_df = wine_df[['price', 'variety']]
sns.set(rc={"figure.figsize":(15, 6)}, style="whitegrid")
g2 = sns.catplot(data=price_variety_df, x='variety', y='price', hue='variety', height=8, aspect=1.5, kind='violin', dodge=False)
g2.set_xticklabels(rotation=90)
g2.set(title = 'violinplot price by variety')

entry_variety_df = wine_df[['id','variety']]
entry_variety_df.rename(columns={'id':'entry count'}, inplace=True)
entry_variety_df.groupby(['variety']).count().plot(kind='pie', y='entry count', ylabel='', autopct='%1.0f%%', figsize=(18,9), legend=False)

sentiment_country_df = wine_df[['sentiment','country']]
sns.set(rc={"figure.figsize":(15, 6)}, style="whitegrid")
g2 = sns.catplot(data=sentiment_country_df, x='country', y='sentiment', hue='country', height=8, aspect=1.5, kind='box', dodge=False)
g2.set_xticklabels(rotation=90)
g2.set(title = 'boxplot sentiment by variety')

sentiment_country_df = wine_df[['sentiment','country']].groupby(['country']).mean().reset_index()
sentiment_country_df.rename(columns={'sentiment':'average sentiment'}, inplace=True)
sns.set(rc={"figure.figsize":(15, 6)}, style="whitegrid")
g3 = sns.catplot(data=sentiment_country_df, x='country', y='average sentiment', height=8, aspect=1.5, kind='bar', dodge=False)
g3.set_xticklabels(rotation=90)
g3.set(title = 'average sentiment by country')

wine_df['price'].plot(kind='kde', xlim=(0,300))

wine_df.to_csv('/content/drive/MyDrive/wine_clean.csv', index=False)

"""# PART 2: Regression Model Evaluation and Hyperparameter Tuning



"""

# Data Wrangling
import pandas as pd
import numpy as np

# drive mount
from google.colab import drive
drive.mount('/content/drive')

# PCA
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

#Regression 
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import r2_score

#Cross Validation
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold

#Model tuning
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import Ridge
from sklearn.linear_model import Lasso

#Metrics
from sklearn.metrics import r2_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import mean_squared_error
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score, recall_score, f1_score

# download clean data for modeling 
wine_df  = pd.read_csv('/content/drive/MyDrive/wine_clean.csv')

wine_df

# TO-DO: One-hot encode on imputed wine_df
wine_df  = pd.get_dummies(data=wine_df, columns=['country','variety'])
wine_df.head(5)

def wineClass(x):
    if x <= 10: return 0
    if 10 < x <= 15: return 1
    if 15 < x <= 20: return 2
    if 20 < x <= 30: return 3
    if 30 < x <= 50: return 4
    if 50 < x <= 100: return 5
    if 100 < x <= 200: return 6
    return 7

wine_df['wine_class'] = wine_df['price'].apply(wineClass)
wine_class_count = wine_df[['wine_class','id']].groupby('wine_class').count().reset_index()
wine_class_count.rename(columns={'id':'count'},inplace=True)
sns.set(style="whitegrid")
g4 = sns.catplot(data=wine_class_count, x='wine_class', y='count', height=8, aspect=1.5, kind='bar', dodge=False)
g4.set(title = 'review count by wine class')

price_sorted_df = wine_df[['price']].sort_values('price')
line_number = len(price_sorted_df.index) // 8
indices_selected = [line_number*m for m in range(1,8)]
price_sorted_df.iloc[indices_selected]

def balancedClass(x):
    if x <= 13: return 0
    if 13 < x <= 17: return 1
    if 17 < x <= 20: return 2
    if 20 < x <= 26: return 3
    if 26 < x <= 34: return 4
    if 34 < x <= 44: return 5
    if 44 < x <= 60: return 6
    return 7

wine_df['wine_class'] = wine_df['price'].apply(balancedClass)
wine_class_count = wine_df[['wine_class','id']].groupby('wine_class').count().reset_index()
wine_class_count.rename(columns={'id':'count'},inplace=True)
sns.set(style="whitegrid")
g4 = sns.catplot(data=wine_class_count, x='wine_class', y='count', height=8, aspect=1.5, kind='bar', dodge=False)
g4.set(title = 'review count by wine class')

numeric_df = wine_df
numeric_df = numeric_df[numeric_df['year']>0]
corr_matrix = numeric_df.corr()
sns.set(rc={"figure.figsize":(8, 8)})
ax = sns.heatmap(corr_matrix, cmap = 'RdYlBu_r', vmin = -1, vmax = 1)
ax.set(title='correlation heatmap')
plt.show()

#split train and test dataset
# Preparing data for train set and test set
X = wine_df.drop(columns=['id', 'price', 'wine_class'])
y = wine_df['wine_class']
X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.2)

# step 1: Trainning model by using all variables
clf = LinearRegression()
clf.fit(X_train1,y_train1)

# step 2. Testing model 
y_pred1 = clf.predict(X_test1)

# step 3: evaluate model 
score = clf.score(X_test1, y_test1)
score

# PCA 

# Preparing data for train set and test set
X = wine_df.drop(columns=['id', 'price', 'wine_class'])
y = wine_df['wine_class']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Intermediate step to address scale-invariance
x_train_scale =  StandardScaler().fit_transform(X_train)
x_test_scale =  StandardScaler().fit_transform(X_test)

# Instantiate and Fit PCA
pca = PCA(n_components = 45)
x_train_pca = pca.fit_transform(x_train_scale)
x_test_pca = pca.transform(x_test_scale)

#  Save the explained variance ratios into variable called "explained_variance_ratios"
np.set_printoptions(suppress=True)
explained_variance_ratios = pca.explained_variance_ratio_

# Save the CUMULATIVE explained variance ratios into variable called "cum_evr"
cum_evr = np.cumsum(explained_variance_ratios)

# Plot
plt.figure(figsize=(12,6))
plt.plot(cum_evr)
# Aesthetics 
plt.title('PCA Analysis')
plt.xlabel('Components') 
plt.ylabel('Explained Variance Ratio')
plt.axhline(0.8)
plt.xlim(1,46)  # x range
x=range(1,46,1) 
plt.xticks(x)    # setting for xticks
plt.show()

# Final PCA: reduce dimensionality to 28 components

# 1: Preparing data for train set and test set
X = wine_df.drop(columns=['id', 'price', 'wine_class'])
y = wine_df['wine_class']

# 2. scale training and testing data
scaler= StandardScaler().fit(X)
X_scale = scaler.transform(X)
X_train_scale, X_test_scale, y_train, y_test = train_test_split(X_scale, y, test_size=0.2, random_state=42)

# 3. transfer to PCA 
pca = PCA(n_components = 28)
pca = pca.fit(X_scale)

X_train_pca = pca.transform(X_train_scale)
X_test_pca = pca.transform(X_test_scale)

# step 1: Preparing data for train set and test set

#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)

# step 2. Trainning model by using all independent variable
clf = LinearRegression()
clf.fit(X_train_pca,y_train)

# step 3. Testing model 
y_pred = clf.predict(X_test_pca)

# step 4: evaluate model 
regression_score = clf.score(X_test_pca,y_test)
regression_score

#import data for Regulazation Model
y_batch = y.to_numpy()
y_batch = y_batch[:, None]

sc = MinMaxScaler()
X_batch=X_scale

print("Features shape {}".format(X_batch.shape))
print("Label shape {}".format(y_batch.shape))

def train_linear_model_with_diff_params(model_type, alpha_values, X_scaled, y, test_size, model_list= None, train_accuracy_list= None, test_accuracy_list=None):
  # initialize the result 
  if train_accuracy_list == None:
    train_accuracy_list = [];
  if test_accuracy_list == None:
    test_accuracy_list = [];

  if model_list == None:
    model_list = [];

  for spec_alpha in alpha_values: 
    # split the training and testing dataset 
    (X_train, X_test, y_train, y_test) = train_test_split(X_scaled, y, test_size= 0.8, random_state=42)
    if model_type == 'Ridge':
      model = Ridge(alpha=spec_alpha, max_iter= 100000);
    if model_type == 'Lasso':
      model = Lasso(alpha= spec_alpha, max_iter= 100000);
    
    model.fit(X_train, y_train);
    model_list.append(model); 
    train_accuracy = model.score(X_train, y_train);
    test_accuracy = model.score(X_test, y_test); 
    train_accuracy_list.append(train_accuracy);
    test_accuracy_list.append(test_accuracy);
    # format the result for better result display 
    spec_alpha = format(spec_alpha, '.6f')
    train_accuracy = format(train_accuracy, '.13f')
    test_accuracy = format(test_accuracy, '.13f')
    print("{} Model with alpha {} Performance || Train_accuracy:{}, Test_accuracy:{}".format(model_type, spec_alpha, train_accuracy, test_accuracy));
  return model_list, train_accuracy_list, test_accuracy_list;

alpha_values_list = [5,4,3,2,1,0.5, 0.1, 0.05, 0.01, 0.005, 1e-3, 5e-4, 1e-4, 5e-5, 1e-5,
                     5e-6, 1e-6, 5e-7, 1e-7];

ridge_model_list, ridge_train_accur_list, ridge_test_accur_list = train_linear_model_with_diff_params(model_type='Ridge', 
                                                                                                        alpha_values= alpha_values_list, 
                                                                                                        X_scaled= X_batch, 
                                                                                                        y= y_batch, 
                                                                                                        test_size = 0.2)

alpha_values_list = [5,4,3,2,1,0.5, 0.1, 0.05, 0.01, 0.005, 1e-3, 5e-4];
lasso_model_list, lasso_train_accur_list, lasso_test_accur_list = train_linear_model_with_diff_params(model_type='Lasso', 
                                                                                                        alpha_values= alpha_values_list, 
                                                                                                        X_scaled= X_batch, 
                                                                                                        y= y_batch, 
                                                                                                        test_size = 0.2)

# PCA 

# Preparing data for train set and test set
X = wine_df.drop(columns=['id', 'price', 'wine_class'])
y = wine_df['wine_class']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Intermediate step to address scale-invariance
x_train_scale =  StandardScaler().fit_transform(X_train)
x_test_scale =  StandardScaler().fit_transform(X_test)

# Instantiate and Fit PCA
pca = PCA(n_components = 45)
x_train_pca = pca.fit_transform(x_train_scale)
x_test_pca = pca.transform(x_test_scale)

#  Save the explained variance ratios into variable called "explained_variance_ratios"
np.set_printoptions(suppress=True)
explained_variance_ratios = pca.explained_variance_ratio_

# Save the CUMULATIVE explained variance ratios into variable called "cum_evr"
cum_evr = np.cumsum(explained_variance_ratios)

# Plot
plt.figure(figsize=(12,6))
plt.plot(cum_evr)
# Aesthetics 
plt.title('PCA Analysis')
plt.xlabel('Components') 
plt.ylabel('Explained Variance Ratio')
plt.axhline(0.8)
plt.xlim(1,46)  # x range
x=range(1,46,1) 
plt.xticks(x)    # setting for xticks
plt.show()

# Final PCA: reduce dimensionality to 28 components

# 1: Preparing data for train set and test set
X = wine_df.drop(columns=['id', 'price', 'wine_class'])
y = wine_df['wine_class']

# 2. scale training and testing data
scaler= StandardScaler().fit(X)
X_scale = scaler.transform(X)
X_train_scale, X_test_scale, y_train, y_test = train_test_split(X_scale, y, test_size=0.2, random_state=42)

# 3. transfer to PCA 
pca = PCA(n_components = 28)
pca = pca.fit(X_scale)

X_train_pca = pca.transform(X_train_scale)
X_test_pca = pca.transform(X_test_scale)

# Training the logistic regression model with Ridge regularization by using PCA data
log_reg_pca = LogisticRegression(penalty='l2', random_state=42, max_iter=5000)
log_reg_pca.fit(X_train_pca, y_train)

#  Use the model to predict on the PCA transformed test set and save these predictions as `y_pred`
y_pred_pca = log_reg_pca.predict(X_test_pca)

# TO-DO: Find the accuracy and store the value in `test_accuracy`
log_reg_score = log_reg_pca.score(X_test_pca, y_test)
print('logistic regression score: {}'.format(log_reg_score))
log_reg_accuracy = accuracy_score(y_test, y_pred_pca)
print('accuracy score: {}'.format(log_reg_accuracy ))

print('Precision: %.3f' %precision_score(y_true=y_test, y_pred=y_pred_pca, labels=[0,1,2,3,4,5,6,7],average='micro'))
print('Recall: %.3f' %recall_score(y_true=y_test, y_pred=y_pred_pca, labels=[0,1,2,3,4,5,6,7],average='micro'))
print('F1: %.3f' %f1_score(y_true=y_test, y_pred=y_pred_pca, labels=[0,1,2,3,4,5,6,7],average='micro'))

import numpy as np
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import roc_auc_score
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc

y_score = log_reg_pca.fit(X_train_pca, y_train).decision_function(X_test_pca)

# Compute ROC curve and ROC area for each class
fpr = dict()
tpr = dict()
roc_auc = dict()

y_test_2 = label_binarize(y_test, classes=[0,1,2,3,4,5,6,7])

n_classes = y_test_2.shape[1]

for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_2[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Compute micro-average ROC curve and ROC area
fpr["micro"], tpr["micro"], _ = roc_curve(y_test_2.ravel(), y_score.ravel(), pos_label=1)
roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])

plt.figure()
lw = 1
plt.style.use('seaborn')
plt.plot(fpr[lw], tpr[lw], color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[lw])
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for Class %d'%lw)
plt.legend(loc="lower right")
plt.show()

from sklearn.model_selection import learning_curve

train_sizes, train_scores, test_scores = \
  learning_curve(estimator=log_reg_pca, X=X_scale,
                 y=y,
                 train_sizes=[0.3, 0.5, 0.6, 0.7, 0.8, 0.85],
                 cv=10)
  
plt.plot(train_sizes,np.mean(train_scores, axis=1), \
          marker='o', label='Training accuracy')
plt.plot(train_sizes,np.mean(test_scores, axis=1), \
          marker='+', label='Validation accuracy')
plt.xlabel('Training samples')
plt.legend()

from sklearn.model_selection import validation_curve
param_range = [0.001, 0.01, 0.01, 1.0, 5.0, 10.0, 15.0, 20.0]

train_scores, test_scores = validation_curve(estimator=log_reg_pca, X=X_scale,
                                             y=y, param_name='C',
                                             param_range = param_range,
                                             cv=10)

train_mean = np.mean(train_scores, axis=1)
train_std = np.std(train_scores, axis=1)
test_mean = np.mean(test_scores, axis=1)
test_std = np.std(test_scores, axis=1)
plt.figure(dpi=100)
plt.plot(param_range, train_mean, color='blue', marker='o',
         markersize=6, label='Training accuracy')
plt.fill_between(param_range, train_mean + train_std, train_mean - train_std, \
                 alpha=0.15)
plt.plot(param_range, test_mean, color='green', marker='+',
         markersize=6, label='Test accuracy')
plt.fill_between(param_range, test_mean + test_std, test_mean - test_std, \
                 alpha=0.15)
plt.xscale('log')
plt.legend(loc='lower left')
plt.ylabel('Accuracy')
plt.xlabel('Regularization parameter C')
plt.show()

"""# PART 3: Random Forest and Neural Network Model"""

# Commented out IPython magic to ensure Python compatibility.
# Data Wrangling
import pandas as pd
import numpy as np

# torch nn
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, TensorDataset
from torch.utils.data import DataLoader, TensorDataset
from torch.autograd import Variable
# from collections import Counter

# sklearn
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestClassifier

# decision tree
from io import StringIO
from sklearn.tree import export_graphviz
from sklearn import tree
from IPython.display import Image  
import pydotplus
import graphviz

#Plotting
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

from google.colab import drive
drive.mount('/content/drive')

wine_df.head(10)

X = wine_df.drop(columns=['id', 'price', 'wine_class'])
y = wine_df['wine_class']
X_batch = X.to_numpy()
y_batch = y.to_numpy()
y_batch = y_batch[:, None]
#min max scale the features
sc = MinMaxScaler()
X_batch=sc.fit_transform(X_batch)

print("Features shape {}".format(X_batch.shape))
print("Label shape {}".format(y_batch.shape))

X_train, X_test, y_train, y_test = train_test_split(X_batch, y_batch, test_size=0.2, random_state=42)
#convert to tensors
X_train = torch.from_numpy(X_train)
X_train = X_train.to(torch.float32)
y_train = torch.from_numpy(y_train)
y_train = y_train.to(torch.float32)
X_test = torch.from_numpy(X_test)
X_test = X_test.to(torch.float32)
y_test = torch.from_numpy(y_test)
y_test = y_test.to(torch.float32)
# check the training tensor and testing tensor size 
print("Training Data Tensor Size: features x:{},  label y:{}".format(X_train.shape, y_train.shape))
print("Testing Data Tensor Size: features x:{},  label y:{}".format(X_test.shape, y_test.shape))

# batch_size
batch_size = 400

# Pytorch train and test sets
train = TensorDataset(X_train,y_train)
test = TensorDataset(X_test,y_test)


# data loader
train_loader = DataLoader(train, batch_size = batch_size, shuffle = False)
test_loader = DataLoader(test, batch_size = batch_size, shuffle = False)

class FNN(nn.Module):
    def __init__(self):
        super().__init__()
        # TODO
        self.flatten = nn.Flatten() 
        self.relu = nn.ReLU()

       #hidden and output layers
        self.input = nn.Linear(45, 20) 
        self.hidden = nn.Linear(20, 15) 
        self.output = nn.Linear(15, 1) #number of classes

    def forward(self, x):
        # TODO
        outputs = nn.Sequential(self.flatten,self.input, self.relu, self.hidden, self.relu, self.output)(x) #similar with pipline     
        # END TODO
        return outputs

torch.manual_seed(42) 
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(torch.__version__)
print(device)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Sending the data to device (CPU or GPU)
# # TODO
# fnn = FNN().to(device)
# 
# criterion = nn.MSELoss()
# # END TODO 
# # optimizer = optim.SGD(fnn.parameters(), lr=1e-4) #lr - learning step(1e-4, 0.1, etc)
# optimizer = optim.Adam(fnn.parameters(), lr=1e-2) #lr - learning step
# epoch = 16
# acc_LIST_FNN = []
# loss_LIST_FNN = []
# 
# # Train the FNN
# for epoch in range(epoch):
#   running_loss = 0.0
#   correct = 0
#   total = 0
#   for inputs, labels in train_loader:
#       labels = labels.type(torch.FloatTensor) # Cast to Float
#       inputs, labels = inputs.to(device), labels.to(device)
#       # inputs, labels = inputs.to(torch.float32).to(device), labels.to(torch.float32).to(device)
#       # print(inputs)
#       # print(labels)
#       # TODO
#       outputs = fnn(inputs) # Feed the network the train data
#       # print(labels)
#       # print(outputs)
#       # _, preds = torch.max(outputs.data, 1)
#       total += labels.size(0)
#       correct += (outputs.to(torch.int) == labels.to(torch.int)).sum().item()
#       optimizer.zero_grad() # We need to reset the optimizer tensor gradient every mini-batch
#       loss = criterion(outputs, labels) # this is the average loss for one mini-batch of inputs
#       loss.backward() # Do a back propagation
#       optimizer.step()
#       running_loss += loss.item()
#       # print(running_loss)
#       # print(correct)
#       
#   accuracy = 100 * correct / total# Calculate Training Acc
#   acc_LIST_FNN.append(accuracy)
#   loss_LIST_FNN.append(running_loss / len(train_loader) ) # get the avg loss for each epoch
#   
#   # END TODO 
# 
#   # print statistics
#   print("The loss for Epoch {} is: {}, Accuracy = {}%, correct: {}, total: {}".format(epoch+1, running_loss/len(train_loader), accuracy, correct, total))

# TODO
epoch = 16
fnn_acc_vs_epoch_data = {'epoch number':[e for e in range(1,epoch+1)], 'training accuracy':acc_LIST_FNN}
fnn_acc_vs_epoch_df = pd.DataFrame.from_dict(data=fnn_acc_vs_epoch_data)
fig, ax = plt.subplots(figsize=(6,4))
ax_train = sns.lineplot(data = fnn_acc_vs_epoch_df, x = 'epoch number', y = 'training accuracy')
ax_train.set(title = 'Training Accuracy vs Epochs FNN')
# END TODO

total = 0
correct = 0
with torch.no_grad():
    for inputs, labels in test_loader:
        labels = labels.type(torch.FloatTensor) # Cast to Float
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = fnn(inputs) # Feed the network the train data
        total += labels.size(0)
        correct += (outputs.to(torch.int) == labels.to(torch.int)).sum().item()

test_acc_FNN = pd.Series([100 * correct / total], copy = False)
# TODO END
print('Test Accuracy: ' + str(test_acc_FNN.item()) +'%')

# batch_size
batch_size = 400

# Pytorch train and test sets
train = TensorDataset(X_train,y_train)
test = TensorDataset(X_test,y_test)


# data loader
train_loader = DataLoader(train, batch_size = batch_size, shuffle = False)
test_loader = DataLoader(test, batch_size = batch_size, shuffle = False)

class DNN(nn.Module):
    def __init__(self):
        super().__init__()
        # TODO
        self.deep_stack = nn.Sequential(
            nn.Flatten(),
            nn.Linear(45,45),
            nn.ReLU(),
            nn.Linear(45,45),
            nn.ReLU(),
            nn.Linear(45,45),
            nn.ReLU(),
            nn.Linear(45,45),
            nn.ReLU(),
            nn.Linear(45,45),
            nn.ReLU(),
            nn.Linear(45,40),
            nn.ReLU(),
            nn.Linear(40,32),
            nn.ReLU(),
            nn.Linear(32,16),
            nn.ReLU(),
            nn.Linear(16,8),
            nn.ReLU(),
            nn.Linear(8,4),
            nn.ReLU(),
            nn.Linear(4,1),
        )
        # END TODO

    def forward(self, x):
        # TODO
        outputs = self.deep_stack(x)
        # END TODO
        return outputs

torch.manual_seed(42) 
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(torch.__version__)
print(device)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Sending the data to device (CPU or GPU)
# # TODO
# dnn = DNN().to(device)
# 
# criterion = nn.MSELoss()
# # END TODO 
# # optimizer = optim.SGD(dnn.parameters(), lr=1e-4) #lr - learning step(1e-4, 0.1, etc)
# optimizer = optim.Adam(dnn.parameters(), lr=1e-2) #lr - learning step
# epoch = 25
# acc_LIST_DNN = []
# loss_LIST_DNN = []
# 
# # Train the DNN
# for epoch in range(epoch):
#   running_loss = 0.0
#   correct = 0
#   total = 0
#   for inputs, labels in train_loader:
#       labels = labels.type(torch.FloatTensor) # Cast to Long
#       inputs, labels = inputs.to(device), labels.to(device)
#       # TODO
#       outputs = dnn(inputs) # Feed the network the train data
#       total += labels.size(0)
#       correct += (outputs.to(torch.int) == labels.to(torch.int)).sum().item()
#       optimizer.zero_grad() # We need to reset the optimizer tensor gradient every mini-batch
#       loss = criterion(outputs, labels) # this is the average loss for one mini-batch of inputs
#       loss.backward() # Do a back propagation
#       optimizer.step()
#       running_loss += loss.item()
#       
#   accuracy = 100 * correct / total# Calculate Training Acc
#   acc_LIST_DNN.append(accuracy)
#   loss_LIST_DNN.append(running_loss / len(train_loader) ) # get the avg loss for each epoch
#   
#   # END TODO 
# 
#   # print statistics
#   # if epoch%10 == 0:
#   print("The loss for Epoch {} is: {}, Accuracy = {}%, correct: {}, total: {}".format(epoch+1, running_loss/len(train_loader), accuracy, correct, total))

# TODO
epoch = 25
dnn_acc_vs_epoch_data = {'epoch number':[e for e in range(1,epoch+1)], 'training accuracy':acc_LIST_DNN}
dnn_acc_vs_epoch_df = pd.DataFrame.from_dict(data=dnn_acc_vs_epoch_data)
fig, ax = plt.subplots(figsize=(6,4))
ax_train = sns.lineplot(data = dnn_acc_vs_epoch_df, x = 'epoch number', y = 'training accuracy')
ax_train.set(title = 'Training Accuracy vs Epochs FNN')
# END TODO

total = 0
correct = 0
with torch.no_grad():
    for inputs, labels in test_loader:
        labels = labels.type(torch.FloatTensor) # Cast to Float
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = dnn(inputs) # Feed the network the train data
        total += labels.size(0)
        correct += (outputs.to(torch.int) == labels.to(torch.int)).sum().item()

test_acc_DNN = pd.Series([100 * correct / total], copy = False)
# TODO END
print('Test Accuracy: ' + str(test_acc_DNN.item()) +'%')

wine_df

X = wine_df.drop(columns=['price', 'wine_class'])
y = wine_df['wine_class']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)
#Fit Model
clf = tree.DecisionTreeClassifier(max_depth = 30,random_state = 1) #If depth is not set, it constructs a very deep tree
clf = clf.fit(X_train, y_train)

# Test Model
print('Training Accuracy = ',clf.score(X_train,y_train)) # training data
print('Testing Accuracy = ',clf.score(X_test,y_test)) # testing data

# dot_data = tree.export_graphviz(clf, out_file=None)  
# graph = pydotplus.graph_from_dot_data(dot_data)  
# Image(graph.create_png())

#Fit Model
X = wine_df.drop(columns=['price', 'wine_class'])
y = wine_df['wine_class']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)
clf = RandomForestClassifier(max_depth = 30)
clf.fit(X_train,y_train)
prediction = clf.predict(X_test)

# Test Model
print('Training Accuracy = ',clf.score(X_train,y_train)) # training data
print('Testing Accuracy = ',clf.score(X_test,y_test)) # testing data